{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82971a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import random\n",
    "from random import shuffle \n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b236ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code taken from\n",
    "#https://towardsdatascience.com/understand-your-algorithm-with-grad-cam-d3b62fce353\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def GradCam(model, img_array, layer_name, eps=1e-8):\n",
    "    '''\n",
    "    Creates a grad-cam heatmap given a model and a layer name contained with that model\n",
    "    \n",
    "\n",
    "    Args:\n",
    "      model: tf model\n",
    "      img_array: (img_width x img_width) numpy array\n",
    "      layer_name: str\n",
    "\n",
    "\n",
    "    Returns \n",
    "      uint8 numpy array with shape (img_height, img_width)\n",
    "\n",
    "    '''\n",
    "\n",
    "    gradModel = Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(layer_name).output,\n",
    "                 model.output])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # cast the image tensor to a float-32 data type, pass the\n",
    "        # image through the gradient model, and grab the loss\n",
    "        # associated with the specific class index\n",
    "        inputs = tf.cast(img_array, tf.float32)\n",
    "        (convOutputs, predictions) = gradModel(inputs)\n",
    "        loss = predictions[:, 0]\n",
    "        # use automatic differentiation to compute the gradients\n",
    "    grads = tape.gradient(loss, convOutputs)\n",
    "    \n",
    "    # compute the guided gradients\n",
    "    castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "    castGrads = tf.cast(grads > 0, \"float32\")\n",
    "    guidedGrads = castConvOutputs * castGrads * grads\n",
    "    \n",
    "    # the convolution and guided gradients have a batch dimension\n",
    "    # (which we don't need) so let's grab the volume itself and\n",
    "    # discard the batch\n",
    "    convOutputs = convOutputs[0]\n",
    "    guidedGrads = guidedGrads[0]\n",
    "    \n",
    "    # compute the average of the gradient values, and using them\n",
    "    # as weights, compute the ponderation of the filters with\n",
    "    # respect to the weights\n",
    "    weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "  \n",
    "    # grab the spatial dimensions of the input image and resize\n",
    "    # the output class activation map to match the input image\n",
    "    # dimensions\n",
    "    (w, h) = (img_array.shape[2], img_array.shape[1])\n",
    "    heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "    \n",
    "    # normalize the heatmap such that all values lie in the range\n",
    "    # [0, 1], scale the resulting values to the range [0, 255],\n",
    "    # and then convert to an unsigned 8-bit integer\n",
    "    numer = heatmap - np.min(heatmap)\n",
    "    denom = (heatmap.max() - heatmap.min()) + eps\n",
    "    heatmap = numer / denom\n",
    "    \n",
    "    # heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "    # return the resulting heatmap to the calling function\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def sigmoid(x, a, b, c):\n",
    "    return c / (1 + np.exp(-a * (x-b)))\n",
    "\n",
    "def superimpose(img_bgr, cam, thresh, emphasize=False):\n",
    "    \n",
    "    '''\n",
    "    Superimposes a grad-cam heatmap onto an image for model interpretation and visualization.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "      image: (img_width x img_height x 3) numpy array\n",
    "      grad-cam heatmap: (img_width x img_width) numpy array\n",
    "      threshold: float\n",
    "      emphasize: boolean\n",
    "\n",
    "    Returns \n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "\n",
    "    '''\n",
    "    heatmap = cv2.resize(cam, (img_bgr.shape[1], img_bgr.shape[0]))\n",
    "    if emphasize:\n",
    "        heatmap = sigmoid(heatmap, 50, thresh, 1)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    hif = .8\n",
    "    superimposed_img = heatmap * hif + img_bgr\n",
    "    superimposed_img = np.minimum(superimposed_img, 255.0).astype(np.uint8)  # scale 0 to 255  \n",
    "    superimposed_img_rgb = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return superimposed_img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666d7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a493dcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 15:31:20.876962: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-12 15:31:20.877394: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "cnn_path = \"/Users/ritvikraina/Models/CNN-trained.h5\"\n",
    "cnn = load_model(cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409a9f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 32)      832       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 124, 124, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 58, 58, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 58, 58, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               409700    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,488,302\n",
      "Trainable params: 1,487,342\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b26066",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y_/2nr8gtzn6jx8b92r63lgs3q80000gn/T/ipykernel_47109/990278513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Conv_1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGradCam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgrad_cam_superimposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuperimpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memphasize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "## Grad-CAM heatmap for the last convolutional layer in the model, Conv_1\n",
    "\n",
    "layer_name = 'Conv_1'\n",
    "grad_cam=GradCam(cnn,np.expand_dims(img, axis=0),layer_name)\n",
    "grad_cam_superimposed = superimpose(img, grad_cam, 0.5, emphasize=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.imshow(grad_cam_superimposed)\n",
    "plt.axis('off')\n",
    "plt.title('Conv_1 Grad-CAM heat-map')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path =\n",
    "resnet = load_model(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef570ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_path =\n",
    "cos = load_model(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
